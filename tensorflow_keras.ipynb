{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A high-level API to build and train deep learning models\n",
    "- Used for fast prototyping, advanced research, and production\n",
    "- User friendly\n",
    "- Modular and composable\n",
    "- Easy to extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q pyyaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import tf.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.keras`\n",
    "- A high-level API to build and train models that includes first class support for TensorFlow-specific functionality\n",
    "- Such as eager execution, `tf.data` pipelines, and Estimators\n",
    "- `tf.keras` makes TensorFlow easier to use without sacrificing flexibiity and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "2.1.6-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.keras` version in the latest TensorFlow might not be the same as the latest `keras` version from PyPI\n",
    "- When saving a model's weights, `tf.keras` defaults to the checkpoint format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assemble layers to build model\n",
    "- A model is (usually) a graph of layers\n",
    "- The most common type of model is a stack of layers: the `tf.keras.Sequential` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple, fully-connected network (i.e. multi-layer perceptron)\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Adds a densely-connected layer with 64 units to the model\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add another\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add a softmax layer with 10 output units\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.keras.layers`\n",
    "- `activation`\n",
    "    - Activation function of the layer\n",
    "    - This parameter is specified by the name of a built-int function or as a callable object\n",
    "    - By default, no activation is applied\n",
    "- `kernel_initializer` and `bias_initializer`\n",
    "    - The initialization schemes that create the layer's weights (kernel and bias)\n",
    "    - This parameter is a name or a callable object\n",
    "    - Defaults to the `Glorot uniform` initializer\n",
    "- `kernel_regularizer` and `bias_regularizer`\n",
    "    - The regularization schemes that apply the layer's weights (kernel and bias)\n",
    "    - Such as L1 or L2 regularization\n",
    "    - By defaults, no regularization is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0xb33a33c18>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating tf.keras.layers.Dense layers using constructor \n",
    "# arguments\n",
    "\n",
    "# Create a sigmoid layer:\n",
    "layers.Dense(64, activation='sigmoid')\n",
    "# Or:\n",
    "# layers.Dense(64, activation=tf.sigmoid)\n",
    "\n",
    "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
    "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "\n",
    "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
    "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
    "layers.Dense(64, kernel_initializer='orthogonal')\n",
    "\n",
    "# A linear layer with a bias vector initialized to 2.0s:\n",
    "layers.Dense(64, bias_initializer=tf.keras.initializers.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluate\n",
    "\n",
    "### Set up training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring the learning process by calling `compile` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "               loss='categorical_crossentrophy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.keras.Model.compile` takes three important arguments:\n",
    "- `optimizer`\n",
    "    - Specifies the training procedure\n",
    "    - Pass the optimizer instances from the `tf.train` module (such as `tf.train.AdamOptimizer`, `tf.train.RMSPropOptimizer`, or `tf.train.GradientDescentOptimizer`\n",
    "- `loss`\n",
    "    - The function to minimize during optimization\n",
    "    - Common choices includes mean square error (`mse`), `categorical_crossentrophy`, and `binary_crossentrophy`\n",
    "    - Loss functions are specified by name or by passing a callable object from the `tf.keras.losses` module\n",
    "- `metrics`\n",
    "    - Used to monitor training\n",
    "    - String names or callables from `tf.keras.metrics` module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring a model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a model for mean-squared error regression\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
    "              loss='mse',       # mean squared error\n",
    "              metrics=['mae'])  # mean absolute error\n",
    "\n",
    "# Configure a model for categorical classification\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input NumPy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is \"fit\" to the training data using the `fit` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 452us/step - loss: 11.5295 - categorical_accuracy: 0.0920\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 11.4875 - categorical_accuracy: 0.0860\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 11.4759 - categorical_accuracy: 0.1120\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 11.4723 - categorical_accuracy: 0.0980\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 11.4680 - categorical_accuracy: 0.1070\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 11.4668 - categorical_accuracy: 0.1070\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 11.4641 - categorical_accuracy: 0.1220\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 11.4576 - categorical_accuracy: 0.1290\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 11.4578 - categorical_accuracy: 0.1300\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 11.4508 - categorical_accuracy: 0.1370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb33a52c50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.keras.Model.fit` takes three important arguments:\n",
    "- `epochs`\n",
    "    - Training is structured into epochs\n",
    "    - An epoch is one iteration over the entire input data (this is done in similar patches)\n",
    "- `batch_size`\n",
    "    - The model slices the data into smaller batches and iterates over these batches during training\n",
    "    - This integer specifies the size of each batch\n",
    "    - The last batch may be smaller if the total number of samples is not divisible by the batch size\n",
    "- `validation_data`\n",
    "    - This parameter is a tuple of inputs and labels\n",
    "    - This allows the model to display the loss and metrics in inference mode for the passed data at the end of each epoch (shown above)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example using `validation_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 209us/step - loss: 11.5204 - categorical_accuracy: 0.1070 - val_loss: 11.6798 - val_categorical_accuracy: 0.1500\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 11.5143 - categorical_accuracy: 0.1050 - val_loss: 11.6878 - val_categorical_accuracy: 0.0600\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 11.5124 - categorical_accuracy: 0.1100 - val_loss: 11.6721 - val_categorical_accuracy: 0.1700\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 11.5120 - categorical_accuracy: 0.0980 - val_loss: 11.6707 - val_categorical_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 11.5093 - categorical_accuracy: 0.1120 - val_loss: 11.6838 - val_categorical_accuracy: 0.1000\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 11.5071 - categorical_accuracy: 0.1200 - val_loss: 11.6867 - val_categorical_accuracy: 0.1000\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 11.5028 - categorical_accuracy: 0.1420 - val_loss: 11.7053 - val_categorical_accuracy: 0.0900\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 11.5009 - categorical_accuracy: 0.1290 - val_loss: 11.6907 - val_categorical_accuracy: 0.1300\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 11.4933 - categorical_accuracy: 0.1380 - val_loss: 11.7136 - val_categorical_accuracy: 0.1400\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 11.4939 - categorical_accuracy: 0.1320 - val_loss: 11.7508 - val_categorical_accuracy: 0.0900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb33f66eb8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.random((100, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32, validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input `tf.data` dadasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 11.4857 - categorical_accuracy: 0.1448\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.5003 - categorical_accuracy: 0.1385\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.5006 - categorical_accuracy: 0.1542\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4906 - categorical_accuracy: 0.1562\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4798 - categorical_accuracy: 0.1521\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4566 - categorical_accuracy: 0.1635\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4195 - categorical_accuracy: 0.1677\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4565 - categorical_accuracy: 0.1854\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4389 - categorical_accuracy: 0.1656\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4384 - categorical_accuracy: 0.1635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb34fb89b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiates a toy dataset instance\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "# Don't forget to specify 'steps_per_epoch' when calling 'fit' on a dataset\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`steps_per_epoch`\n",
    "- The number of training steps the model runs before it moves to the next epoch\n",
    "\n",
    "Since the `Dataset` yields batches of data, this snippet does not require a `batch_size`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets can also be used for validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 11.4305 - categorical_accuracy: 0.1771 - val_loss: 11.7654 - val_categorical_accuracy: 0.1146\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4431 - categorical_accuracy: 0.1781 - val_loss: 11.8875 - val_categorical_accuracy: 0.1146\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4470 - categorical_accuracy: 0.2010 - val_loss: 11.9328 - val_categorical_accuracy: 0.0625\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4398 - categorical_accuracy: 0.1969 - val_loss: 11.6849 - val_categorical_accuracy: 0.0521\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4258 - categorical_accuracy: 0.1906 - val_loss: 11.7790 - val_categorical_accuracy: 0.0833\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4093 - categorical_accuracy: 0.1896 - val_loss: 11.8652 - val_categorical_accuracy: 0.1146\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.3723 - categorical_accuracy: 0.1875 - val_loss: 11.9334 - val_categorical_accuracy: 0.1250\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4132 - categorical_accuracy: 0.2031 - val_loss: 11.7550 - val_categorical_accuracy: 0.0625\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.3946 - categorical_accuracy: 0.1885 - val_loss: 11.8283 - val_categorical_accuracy: 0.0833\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.3939 - categorical_accuracy: 0.1969 - val_loss: 11.9886 - val_categorical_accuracy: 0.0312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x10448da20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32).repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
    "val_dataset = val_dataset.batch(32).repeat()\n",
    "\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and predict\n",
    "\n",
    "The `tf.keras.Model.evaluate` and `tf.keras.Model.predict` methods can use Numpy data and a `tf.data.Dataset`.\n",
    "\n",
    "To evaluate the inference-mode loss and metrics for the data provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 144us/step\n",
      "30/30 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.427550125122071, 0.203125]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.evaluate(data, labels, batch_size=32)\n",
    "model.evaluate(dataset, steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the output of the last layer in inference for the data provided, as a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(data, batch_size=32)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
